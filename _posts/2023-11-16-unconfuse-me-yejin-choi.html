---
layout: magazine
title: "Yejin Choi : AI가 똑똑하면서도 멍청한 이유"
description: "워싱턴대 최예진 교수가 Bill Gates와 함께 AI의 블랙박스 문제, 상식 추론, AGI의 가능성에 대해 솔직한 대화를 나눕니다"
date: 2023-11-16
---
    <header class="magazine-header">
        <div class="logo">Unconfuse<span>Me</span></div>
        <div class="episode-info">Episode 05 · November 16, 2023</div>
    </header>

    <section class="hero">
        <div class="hero-content">
            <span class="hero-label">AI Deep Dive</span>
            <h1 class="hero-title">
                Why AI is <br>
                <span class="highlight">Incredibly Smart</span><br>
                and Shockingly <span class="highlight">Stupid</span>
            </h1>
            <p class="hero-subtitle">
                빌 게이츠와 최예진 교수가 나누는 AI의 현재와 미래에 대한 솔직한 대화. 
                블랙박스 문제부터 AGI까지, AI 기술의 빛과 그림자를 탐구한다.
            </p>
            <div class="guests">
                <div class="guest">
                    <div class="guest-avatar">BG</div>
                    <div class="guest-info">
                        <h4>Bill Gates</h4>
                        <p>Microsoft 창립자</p>
                    </div>
                </div>
                <div class="guest">
                    <div class="guest-avatar">YC</div>
                    <div class="guest-info">
                        <h4>Yejin Choi (최예진)</h4>
                        <p>UW 교수 · MacArthur Fellow</p>
                    </div>
                </div>
            </div>
        </div>
        <div class="hero-visual">
            <div class="visual-text">AI</div>
        </div>
    </section>

    <section class="key-insight">
        <div class="insight-content">
            <span class="insight-label">Key Insight</span>
            <blockquote class="insight-quote">
                "Current AI, the fact that it's so opaque, and nobody knows what's going on under the hood — that's just not healthy."
            </blockquote>
            <p class="insight-translation">
                "현재 AI는 너무 불투명하고, 아무도 그 내부에서 무슨 일이 벌어지는지 모릅니다 — 이건 건강하지 않아요."
            </p>
        </div>
    </section>

    <main class="magazine-grid">
        <!-- Section 1 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">01</span>
                <h2 class="section-title">AI의 블랙박스 문제</h2>
                <p class="question">현재 AI 모델은 왜 이해하기 어려운가요?</p>
                <div class="text-content">
                    <p class="answer">우리가 AI 모델을 만들었지만, 지식이 어떻게 인코딩되어 있는지 실제로 이해하지 못합니다. 내부를 볼 수 있음에도 불구하고 거의 블랙박스와 같아서, 왜 특정 작업을 잘하거나 못하는지 파악하기 어렵습니다. 흥미로운 점은 프롬프트를 조금만 바꿔도 결과가 완전히 달라진다는 것입니다. "당신은 추론을 정말 잘합니다"라고 말해주면 성능이 좋아지는 현상은 마치 사람에게 동기부여하는 것과 비슷합니다. 이러한 불투명성은 AI를 신뢰하기 어렵게 만들고, 예상치 못한 실패에 취약하게 합니다.</p>
                </div>
            </div>
            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">LLM <span class="en">Large Language Model</span></h4>
                    <p class="knowledge-desc">방대한 텍스트 데이터를 학습하여 인간처럼 글을 읽고 쓸 수 있는 AI입니다. GPT-4, Claude 등이 대표적이며, "다음에 올 단어 예측"이라는 단순한 원리로 놀라운 능력을 보여주지만 그 작동 방식은 여전히 불투명합니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">프롬프트 엔지니어링 <span class="en">Prompt Engineering</span></h4>
                    <p class="knowledge-desc">AI에게 질문하거나 지시하는 방식을 최적화하는 기술입니다. 같은 질문도 어떻게 표현하느냐에 따라 AI의 답변 품질이 크게 달라집니다.</p>
                </div>
            </aside>
        </article>

        <!-- Section 2 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">02</span>
                <h2 class="section-title">AI의 규모 확장과 한계</h2>
                <p class="question">AI 모델을 더 크게 만들면 성능이 계속 좋아질까요?</p>
                <div class="text-content">
                    <p class="answer">GPT-3에서 GPT-4로 넘어갈 때 극적인 개선이 있었지만, 앞으로도 같은 향상이 계속될지는 불확실합니다. 한쪽에서는 규모를 키우면 모든 문제가 해결된다고 믿지만, 다른 한쪽에서는 근본적인 한계가 있어 더 효율적인 방법이 필요하다고 봅니다. 최예진 교수는 후자의 입장으로, 현재의 "무식하게 크게 만들기" 방식이 지능의 올바른 방법이 아니라고 생각합니다. 첫 번째 PC, 첫 번째 스마트폰처럼 최초의 발명이 최적의 해결책인 적은 없었습니다.</p>
                </div>
            </div>
            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">스케일링 법칙 <span class="en">Scaling Laws</span></h4>
                    <p class="knowledge-desc">AI 모델의 크기, 데이터 양, 컴퓨팅 파워를 늘리면 성능이 예측 가능하게 향상된다는 관찰입니다. 하지만 이것이 무한히 지속될지, 아니면 어느 시점에서 한계에 부딪힐지는 AI 연구의 핵심 논쟁입니다.</p>
                </div>
            </aside>
        </article>

        <!-- Section 3 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">03</span>
                <h2 class="section-title">AI의 수학과 추론 능력</h2>
                <p class="question">AI가 수학이나 논리적 추론을 어려워하는 이유는 무엇인가요?</p>
                <div class="text-content">
                    <p class="answer">역설적이게도 AI는 간단한 스도쿠 퍼즐도 풀지 못하는 경우가 있습니다. 기호적 추론이나 사실 기반 지식이 필요한 작업에서 취약한데, 이는 LLM이 최적화하는 수학적 방정식을 보면 그런 능력이 갑자기 나타날 이유가 없기 때문입니다. 인간은 작은 작업 기억을 가지고 즉시 추상화하는 반면, GPT-4는 거대한 작업 기억에 의존해 표면적 패턴에만 집중합니다. 이것이 오히려 진정한 개념 이해를 방해하는 병목이 될 수 있습니다.</p>
                </div>
            </div>
            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">기호적 추론 <span class="en">Symbolic Reasoning</span></h4>
                    <p class="knowledge-desc">논리 규칙과 기호를 사용해 단계별로 결론을 도출하는 사고방식입니다. "A이면 B이고, B이면 C이므로, A이면 C이다"처럼 명확한 규칙을 따르는 추론입니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">작업 기억 <span class="en">Working Memory</span></h4>
                    <p class="knowledge-desc">정보를 일시적으로 저장하고 처리하는 인지 능력입니다. 인간은 약 7개 항목만 기억하지만 즉시 핵심을 추상화합니다. GPT-4는 수만 단어를 기억합니다.</p>
                </div>
            </aside>
        </article>

        <!-- Stats Section -->
        <section class="full-width-section">
            <div class="stat-card">
                <div class="stat-number">10×</div>
                <div class="stat-label">GPT-3 → GPT-4 규모 증가</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">2-3년</div>
                <div class="stat-label">수학 튜터 AI 예상 개발 기간</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">7개</div>
                <div class="stat-label">인간 작업 기억 용량 (항목)</div>
            </div>
        </section>

        <!-- Section 4 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">04</span>
                <h2 class="section-title">소형 특화 모델의 가능성</h2>
                <p class="question">작은 AI 모델도 대형 모델을 이길 수 있나요?</p>
                <div class="text-content">
                    <p class="answer">특정 목표 작업이 있다면, 작은 모델이 대형 모델의 격차를 좁히고 심지어 능가할 수 있습니다. 핵심은 더 많은 데이터가 아니라 더 좋은 데이터입니다. 인간도 랜덤한 웹 데이터를 읽어서 잘 배우지 않듯이, 잘 설계된 교과서와 튜토리얼로 배울 때 더 효과적입니다. 게이츠 재단이 추진하는 수학 튜터 같은 교육용 AI는 2-3년 내에 상당히 발전할 것으로 기대됩니다. 실수의 위험이 낮은 영역부터 시작하는 것이 현명한 접근입니다.</p>
                </div>
            </div>
            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">파인튜닝 <span class="en">Fine-tuning</span></h4>
                    <p class="knowledge-desc">범용 AI 모델을 특정 분야의 데이터로 추가 학습시켜 전문화하는 과정입니다. 의료, 법률, 교육 등 특정 영역에서 더 정확한 성능을 얻을 수 있으며, 대형 모델보다 적은 컴퓨팅으로도 뛰어난 결과를 낼 수 있습니다.</p>
                </div>
            </aside>
        </article>

        <!-- Section 5 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">05</span>
                <h2 class="section-title">AI 권력 집중의 위험성</h2>
                <p class="question">AI 기술이 소수 기업에 집중되는 것이 왜 문제인가요?</p>
                <div class="text-content">
                    <p class="answer">컴퓨터 과학 역사상 대부분의 혁신은 대학에서 나왔는데, 현재 AI는 소수의 기술 기업만 접근할 수 있습니다. 학계는 연구할 컴퓨팅 자원조차 없고, GPT-4가 공개되어도 돌릴 컴퓨터가 없습니다. 오픈소스 노력이 빠르게 따라잡고 있지만, 모든 회사가 ChatGPT를 따라잡아야 한다는 압박감 속에서 같은 방향으로만 달려가는 것은 건강하지 않습니다. 다양한 접근법 탐색과 안전 연구에 더 많은 노력이 필요합니다.</p>
                </div>
            </div>
            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">오픈소스 AI <span class="en">Open Source AI</span></h4>
                    <p class="knowledge-desc">누구나 무료로 사용하고 수정할 수 있도록 공개된 AI 모델입니다. Meta의 LLaMA, Mistral 등이 대표적이며, 기업 독점에 대항해 AI 민주화를 추구합니다. 다만 공개해도 실행에 필요한 컴퓨팅 자원이 막대해서 실질적 접근성에는 한계가 있습니다.</p>
                </div>
            </aside>
        </article>

        <!-- Section 6 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">06</span>
                <h2 class="section-title">모라벡의 역설과 생성 AI 역설</h2>
                <p class="question">인간에게 쉬운 것이 AI에게는 왜 어려운가요?</p>
                <div class="text-content">
                    <p class="answer">모라벡의 역설에 따르면, 인간에게 쉬워 보이는 지각 작업(물건 집기)이 AI에게는 어렵고, 어려워 보이는 체스가 AI에게는 쉽습니다. 빌 게이츠도 로봇이 글쓰기 AI보다 먼저 나올 줄 알았다고 놀라워했습니다. 최예진 교수는 여기에 "생성 AI 역설"을 추가합니다: 인간은 소설을 이해하지만 쓰기 어렵고, 그림을 감상하지만 그리기 어렵습니다. AI는 반대로 놀라운 이미지를 생성하지만 이미지 내용을 진정으로 이해하는 데는 뒤처집니다.</p>
                </div>
            </div>
            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">모라벡의 역설 <span class="en">Moravec's Paradox</span></h4>
                    <p class="knowledge-desc">1980년대 로봇공학자 한스 모라벡이 관찰한 현상으로, 고급 추론은 컴퓨터에 쉽지만 감각-운동 기술은 어렵다는 역설입니다. 2살짜리 아이도 하는 걷기와 물건 잡기가 최첨단 로봇에게는 극도로 어렵습니다.</p>
                </div>
            </aside>
        </article>

        <!-- Section 7 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">07</span>
                <h2 class="section-title">AI와 인류의 미래</h2>
                <p class="question">AI가 인류에게 어떤 도움을 줄 수 있을까요?</p>
                <div class="text-content">
                    <p class="answer">최예진 교수의 바람은 AI가 인간 스스로보다 인간을 더 잘 이해하는 것입니다. 갈등과 의견 불일치의 근본 원인이 상호 이해 부족이라면, AI가 우리 자신을 더 잘 성찰하고 서로 소통하며 평화롭게 공존하는 도구가 될 수 있습니다. 빌 게이츠도 AI가 양극화 추세를 역전시킬 수 있다면 세계에 엄청난 기여가 될 것이라고 동의했습니다. 다른 기술이 수소폭탄과 생물테러 병원체를 만들어낸 것처럼, AI의 방향은 우리가 어떻게 사용하느냐에 달려있습니다.</p>
                </div>
            </div>
            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">AGI <span class="en">Artificial General Intelligence</span></h4>
                    <p class="knowledge-desc">인간처럼 어떤 지적 작업이든 수행할 수 있는 AI입니다. 현재 AI는 특정 작업에만 뛰어난 "좁은 AI"인 반면, AGI는 기후 변화 같은 인류의 난제를 해결할 수 있을 것으로 기대됩니다. 하지만 언제, 어떻게 도달할지는 여전히 논쟁 중입니다.</p>
                </div>
            </aside>
        </article>
    </main>

    <footer class="magazine-footer">
        <p class="footer-quote">
            "Evolution somehow figured out the algorithm behind our amazing learning capabilities, but we humans haven't figured out the AI version of it yet."
        </p>
        <p class="footer-meta">
            Unconfuse Me with Bill Gates · Produced by The Gates Notes · 2023
        </p>
    </footer>
