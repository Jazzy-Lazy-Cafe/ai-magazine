---
layout: magazine
title: "Yejin Choi: AI의 놀라운 능력과 충격적인 한계"
description: "워싱턴 대학교 교수이자 맥아더 펠로우인 Yejin Choi가 Bill Gates와 나눈 대화에서 AI의 불투명성, 상식 추론의 한계, 그리고 더 나은 AI를 위한 대안적 접근을 탐구합니다."
date: 2023-11-16
---

{% include magazine/header.html
   logo_text="Unconfuse"
   logo_highlight="Me"
   episode_info="Episode 05 · November 16, 2023" %}

{% include magazine/hero-split.html
   label="AI INTELLIGENCE"
   title="AI는 왜 <span class='highlight'>놀랍도록 똑똑하면서</span> 충격적으로 멍청한가"
   subtitle="현재 AI의 불투명성과 예측 불가능한 실패 모드를 이해하고, 더 효율적이고 신뢰할 수 있는 AI를 향한 대안적 접근을 모색합니다."
   guest1_initials="YC"
   guest1_name="Yejin Choi"
   guest1_role="University of Washington Professor / MacArthur Fellow"
   guest2_initials="BG"
   guest2_name="Bill Gates"
   guest2_role="Microsoft Co-founder / Philanthropist"
   visual_text="AI"
   original_link="https://www.gatesnotes.com/meet-bill/my-podcasts/reader/unconfuse-me-podcast-with-guest-yejin-choi" %}

{% include magazine/highlight-box.html
   label="Core Insight"
   text="Current AI, the fact that it's so opaque, and nobody knows what's going on under the hood - that's just not healthy."
   translation="현재 AI는 너무나 불투명하고, 그 내부에서 무슨 일이 일어나는지 아무도 모릅니다. 이것은 건강하지 않습니다." %}

<!-- Main Content Grid -->
<main class="magazine-grid">

        <!-- SECTION 01: AI의 예측 불가능한 성능 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">01</span>
                <h2 class="section-title">AI의 예측 불가능한 성능</h2>
                <p class="question">AI는 왜 어떤 테스트에서는 극도로 뛰어나면서 다른 곳에서는 어리석은 실수를 하나요?</p>
                <div class="text-content">
                    <p class="answer">저는 지난 몇 년간의 발전에 깜짝 놀랐습니다. 이렇게 인상적일 거라고는 상상하지 못했죠. 하지만 대형 언어 모델(LLM)이 지식을 습득하는 방식에는 뭔가 이상한 점이 있습니다. 이들은 어떤 테스트에서는 극도로 뛰어난 성능을 보이지만, 다른 곳에서는 우리를 놀라게 하는 어리석은 실수를 합니다. 흥미롭게도 실수를 하더라도 프롬프트를 조금만 바꾸면 갑자기 경계가 모호해집니다. 이것이 바로 '프롬프트 엔지니어링'이 일종의 블랙 아트가 된 이유입니다. 어떤 사람들은 트랜스포머를 마치 사람을 동기부여하듯이 해야 한다고 말하기도 합니다. '당신은 추론에 뛰어나고, 정말 신중하게 생각합니다'라고 먼저 말하면 성능이 더 좋아진다는 것이죠. 이는 두 가지 극단적인 반응을 불러일으킵니다. 한쪽에서는 성공 사례에만 집중하여 '하나라도 정답이 있으면 LLM이 정답을 알고 있다'고 생각하고, 다른 한쪽에서는 실패 사례에만 집중하여 '아무것도 작동하지 않는다'고 생각합니다. 답은 그 중간 어딘가에 있을 것입니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">대형 언어 모델 <span class="en">Large Language Models (LLMs)</span></h4>
                    <p class="knowledge-desc">방대한 텍스트 데이터로 학습된 AI 시스템으로 GPT-4, ChatGPT 등이 대표적입니다. 텍스트 패턴을 학습하여 다양한 작업을 수행하지만, 그 내부 작동 방식은 불투명합니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">프롬프트 엔지니어링 <span class="en">Prompt Engineering</span></h4>
                    <p class="knowledge-desc">AI 모델로부터 원하는 결과를 얻기 위해 질문이나 지시를 정교하게 설계하는 기술입니다. 같은 질문이라도 표현 방식에 따라 AI의 응답이 크게 달라질 수 있습니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 02: 규모 확장의 한계 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">02</span>
                <h2 class="section-title">규모 확장의 한계</h2>
                <p class="question">모델의 크기를 10배, 20배 키우면 성능이 극적으로 향상될까요?</p>
                <div class="text-content">
                    <p class="answer">정직하게 말하면 저도 잘 모르겠습니다. 불확실성이 있다는 것이 제가 말하고 싶은 것입니다. 규모를 키워 능력이 다시 한번 향상될 가능성이 높다고 생각하지만, 동시에 이상한 실패 모드에도 놀라게 될 것입니다. 점점 더 평가가 어려워질 것이라고 생각합니다. 왜냐하면 사람들은 성공 사례를 믿는 쪽으로 인지 편향이 있기 때문입니다. 익숙한 사례에는 잘 적응하지만, 정말로 신뢰하기 시작하면 예상치 못한 실패로 배신당할 수 있습니다. 과학계의 반응은 분열되어 있습니다. 한쪽에서는 규모를 키우면 모든 문제가 해결될 것이라 믿고, 다른 쪽에서는 근본적인 한계가 있으며 훨씬 더 효율적인 다른 방법이 있을 것이라 믿습니다. 저는 후자를 믿습니다. 상징적 추론이나 사실적 지식이 필요한 것은 취약할 수 있습니다. 우리가 최적화하는 단순한 방정식을 보면 그런 능력이 갑자기 나타날 이유가 없기 때문입니다.</p>
                </div>
                <p class="follow-up-question">수학처럼 AI가 상대적으로 약한 분야가 있는 이유는 무엇인가요?</p>
                <div class="follow-up-content">
                    <p class="follow-up-answer">수학은 일반적인 추론과 관련이 있는데, 이 부분에서 ChatGPT는 현재 신뢰할 만하지 않습니다. 간단한 스도쿠 퍼즐조차 풀지 못한다는 것은 거의 웃기는 일입니다. 인간도 할 수 있는 일인데 말이죠. 지금 GPT-4 같은 트랜스포머는 엄청나게 큰 작업 메모리를 가지고 있습니다. 반면 우리 인간은 매우 작은 작업 메모리를 가지고 있죠. 우리는 새로운 문장을 들으면 정확히 뭐라고 했는지는 잊어버리지만 추상적인 내용은 기억합니다. 순간적으로 추상화하는 놀라운 능력을 가지고 있는 것입니다. 그런데 GPT-4는 엄청난 작업 메모리를 가지고 있지만, 이것이 오히려 병목현상이 되어 학습 방식을 해치고 있다고 생각합니다. 텍스트 아래의 진정한 개념을 추상화하려고 하기보다는 표면적인 패턴에만 의존하고 있기 때문입니다.</p>
                </div>
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">상징적 추론 <span class="en">Symbolic Reasoning</span></h4>
                    <p class="knowledge-desc">논리적 규칙과 기호를 사용하여 문제를 해결하는 능력입니다. 수학 문제나 퍼즐 풀이처럼 명확한 논리적 단계가 필요한 작업에서 중요합니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">작업 메모리 <span class="en">Working Memory</span></h4>
                    <p class="knowledge-desc">정보를 일시적으로 저장하고 처리하는 인지 능력입니다. 인간은 작은 작업 메모리를 가지지만 효율적으로 추상화하는 반면, AI는 큰 메모리를 가지지만 추상화 능력이 부족합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 03: 특화된 소형 모델의 가능성 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">03</span>
                <h2 class="section-title">특화된 소형 모델의 가능성</h2>
                <p class="question">수학 튜터처럼 특정 목적을 위해서는 작은 모델로도 충분할까요?</p>
                <div class="text-content">
                    <p class="answer">학계에서는 적은 컴퓨팅 자원으로 특화 모델을 개발하려는 노력이 많습니다. 제 연구도 포함해서요. 보통 작은 모델은 모든 차원에서 ChatGPT를 이길 수 없지만, 수학 튜터링처럼 목표 작업이 있다면, 작은 모델로도 격차를 좁힐 수 있을 뿐만 아니라 그 작업에 특화하여 대형 모델의 능력을 실제로 능가할 수 있습니다. 이것은 완전히 가능하며 저는 그것을 믿습니다. 약물 발견 같은 경우 영어를 아는 것이 필요 없습니다. 이상하게도 이런 모델들은 너무 커서 극소수의 사람들만 탐색하거나 변경할 수 있습니다. 컴퓨터 과학 세계에서는 발명된 거의 모든 것이 대학에서 발명되었는데, 사람들이 이것을 가지고 놀 수 있는 형태가 아니라는 것은 문제입니다. 수백 가지 다른 접근법을 시도해볼 수 있도록 대학들이 이런 것들을 밀어붙이고 내부를 들여다볼 수 있는 방법을 찾아야 합니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">전이 학습 <span class="en">Transfer Learning</span></h4>
                    <p class="knowledge-desc">하나의 작업에서 학습한 지식을 다른 관련 작업에 적용하는 기술입니다. 작은 특화 모델은 특정 도메인의 데이터로 효율적으로 학습하여 대형 범용 모델을 능가할 수 있습니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 04: AI의 불투명성 문제 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">04</span>
                <h2 class="section-title">AI의 불투명성 문제</h2>
                <p class="question">현재 AI가 소수의 기업에만 집중되어 있는 것이 왜 문제인가요?</p>
                <div class="text-content">
                    <p class="answer">저도 완전히 동의합니다. 주요 AI가 소수의 기술 기업에만 있고 아무도 내부에서 무슨 일이 일어나는지 모른다는 것은 건강하지 않습니다. 특히 조사하고 더 잘 이해하고 통제할 수 있는 중간 크기의 오픈 솔루션이 있을 가능성이 매우 높을 때 더욱 그렇습니다. 오픈하면 맞춤 사용 사례에 적용하기가 훨씬 쉽습니다. 현재 GPT-4를 사용하는 방식은 프롬프트 엔지니어링을 하고 이해했기를 바라는 것뿐입니다. 수학 튜터링의 경우 언어 모델이 이미 온라인에서 많은 교육 자료를 봤기 때문에 실제로 훨씬 더 가까이 와 있습니다. 반면 약물 발견은 AI가 아직 존재하지 않는 새로운 것을 만들어내야 하는 도전입니다. 이것은 단순히 '시퀀스가 많으니 다음에 올 것을 예측하고 운이 좋기를' 바라는 것이 아니라, 진정으로 지식에 기반한 상징적 방식으로 추론해야 합니다. 현재 학습은 믿을 수 없을 정도로 무식한 방법이며, 이것이 지능을 만드는 올바른 방법이라고 생각하지 않습니다. 더 나은 솔루션이 있을 것입니다. 그리고 그것을 위해서는 오픈해야 합니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">오픈소스 AI <span class="en">Open Source AI</span></h4>
                    <p class="knowledge-desc">AI 모델의 코드와 가중치를 공개하여 누구나 연구하고 수정할 수 있도록 하는 접근입니다. 투명성과 혁신을 촉진하지만, 최대 규모의 모델은 실행에 필요한 컴퓨팅 자원 때문에 접근성이 제한적입니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 05: 설명 가능하고 통제 가능한 AI -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">05</span>
                <h2 class="section-title">설명 가능하고 통제 가능한 AI</h2>
                <p class="question">AI가 실수했을 때 이를 어떻게 교정하고 통제할 수 있을까요?</p>
                <div class="text-content">
                    <p class="answer">저는 기계에 설명 가능하고 서술적인 지식을 제공하여 진정으로 학습하고 기억할 수 있는 시스템을 만들기 위해 노력하고 있습니다. 그리고 실수를 했을 때 '어떤 지식을 가정하고 있나요?'라고 물어보고, '당신의 가정이 틀렸습니다. 이제부터 이 지식을 배우세요'라고 제공할 수 있어야 합니다. 이런 문제들은 정말 흥미로운 새로운 유형의 기계 학습 문제를 열어줍니다. 학습뿐만 아니라 학습 해제(unlearn)를 할 수 있어야 하고, 잘못된 지식을 수정할 수 있어야 합니다. 인간도 할 수 있는 방식이죠. 지금은 모든 것이 너무 블랙박스입니다. 하지만 노력하면 이런 종류의 기술이 가능하다고 생각합니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">기계 학습 해제 <span class="en">Machine Unlearning</span></h4>
                    <p class="knowledge-desc">AI 모델이 학습한 특정 정보나 패턴을 의도적으로 제거하는 기술입니다. 잘못된 지식을 교정하거나 개인정보를 삭제하는 데 중요합니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">설명 가능한 AI <span class="en">Explainable AI (XAI)</span></h4>
                    <p class="knowledge-desc">AI의 의사결정 과정을 인간이 이해할 수 있도록 투명하게 만드는 기술입니다. 블랙박스 모델과 달리, 왜 특정 결론에 도달했는지 설명할 수 있어야 합니다.</p>
                </div>
            </aside>
        </article>

{% include magazine/highlight-box.html
   label="Key Challenge"
   text="We need to be able to unlearn, not just learn, but unlearn the incorrect knowledge, and then be able to revise over that in the way that humans also are able to." %}

        <!-- SECTION 06: 인간 지능과 AI의 알고리즘 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">06</span>
                <h2 class="section-title">인간 지능과 AI의 알고리즘</h2>
                <p class="question">진화가 발견한 인간 뇌의 알고리즘과 AI가 유사할까요?</p>
                <div class="text-content">
                    <p class="answer">진화가 어떻게든 우리의 놀라운 학습 능력 뒤의 알고리즘을 알아냈지만, 우리 인간은 아직 그것의 AI 버전을 찾아내지 못했습니다. 분명히 우리가 아직 발견하지 못한 더 나은 알고리즘이 있다고 생각합니다. 지금은 '더 크게 만들자'에 너무 많은 초점이 맞춰져 있고 모두가 그것을 시도하고 있습니다. 반면에 정말로 더 나은 솔루션, 발견되기를 기다리는 대안적 솔루션이 있을 수 있지만, 그곳에 충분한 관심이 없습니다. 사람들은 '그건 작동하지 않을 거야'라고 생각하는 경향이 있기 때문입니다. Microsoft와 최초의 개인용 컴퓨터를 생각해보세요. 처음 나왔을 때는 정말 흥미롭고 놀라웠습니다. 그런 다음 매년 더 나은 컴퓨터, 더 작은 컴퓨터, 더 빠른 컴퓨터가 나왔습니다. 마찬가지로 폰, 로켓, 자동차를 보면 - 첫 번째 발명은 결코 최적의 솔루션이 아닙니다. 항상 더 나은 솔루션이 있습니다. 더 나은 솔루션이 있다고 생각하지만, 지금은 '크면 클수록 좋다'에 너무 많은 강조가 있습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">신경망 아키텍처 <span class="en">Neural Network Architecture</span></h4>
                    <p class="knowledge-desc">인간 뇌의 뉴런 구조에서 영감을 받은 AI 모델의 설계입니다. 시각 인식 등 일부 영역에서는 인간과 유사한 실수 패턴을 보여 공통된 알고리즘의 존재를 시사합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 07: 데이터의 질과 효율성 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">07</span>
                <h2 class="section-title">데이터의 질과 효율성</h2>
                <p class="question">무조건 큰 모델보다 좋은 데이터가 더 중요한 이유는 무엇인가요?</p>
                <div class="text-content">
                    <p class="answer">현재는 규모를 늘리는 무식한 방법이 주류이지만, 대안이 있을 수 있습니다. 때로는 작은 모델들, 특화된 모델들이 훨씬 더 전문화된 데이터로 학습하는데, 데이터가 실제로 핵심입니다. 그 데이터는 단순히 더 많은 데이터가 아니라 더 나은 데이터, 고품질 데이터일 수 있습니다. 때로는 특정 수학적 개념을 가르치기 위해 실제로 설계된 데이터일 수도 있습니다. 인간도 마찬가지로, 아무도 무작위 웹 데이터를 읽는 것만으로는 잘 배우지 못합니다. 훌륭한 교과서와 튜토리얼이 있을 때 더 잘 배우는 경향이 있습니다. 마찬가지로, 이것은 지식이나 정보를 가장 효율적인 방식으로 전달하는 방법에 관한 것이라고 생각합니다. 그것이 작은 모델이나 중간 크기 모델이 주요한 우위를 가질 수 있다고 믿는 또 다른 이유입니다. 하지만 그것은 그 정보를 대안적으로 얻는 방법에 대한 혁신이 필요합니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">데이터 큐레이션 <span class="en">Data Curation</span></h4>
                    <p class="knowledge-desc">AI 학습을 위해 고품질 데이터를 선별하고 정제하는 과정입니다. 무작위 웹 데이터보다 체계적으로 설계된 교육 자료가 훨씬 효율적인 학습을 가능하게 합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 08: 모라벡의 역설과 생성 AI의 역설 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">08</span>
                <h2 class="section-title">모라벡의 역설과 생성 AI의 역설</h2>
                <p class="question">왜 AI는 인간에게 쉬운 일을 어려워하고 어려운 일을 쉬워하나요?</p>
                <div class="text-content">
                    <p class="answer">정말 예리한 관찰입니다. 실제로 이에 대한 개념이 있는데, 모라벡의 역설(Moravec's Paradox)이라고 합니다. 인간에게 쉬워 보이는 지각 작업이 실제로는 AI에게 훨씬 더 어렵고, 반면에 우리에게 어려운 체스 게임은 실제로 AI에게 더 쉽다는 것입니다. 사실, 그 역전은 다른 방식으로도 일어납니다. 저는 현재 생성 AI 역설(Generative AI Paradox)이라는 생각을 제안하고 있습니다. 어쩌면 생성 능력이 이해 능력보다 더 강할 수 있다는 것인데, 이것도 인간이 하는 방식과 약간 역전된 버전일 수 있습니다. 우리는 놀라운 소설을 이해할 수 있지만 쓰기는 더 어렵다고 느낍니다. 마찬가지로, 우리는 훌륭한 그림을 생성할 수 없어도 감상할 수 있습니다. 반면 지금은 이러한 능력이 약간 역전된 것처럼 보입니다. DALL-E 2, DALL-E 3을 보면 놀라운 이미지를 생성할 수 있지만, 우리를 놀라게 할 만큼 이미지 내용을 진정으로 이해하는 현재의 AI는 없습니다. 이상하게도 뒤처져 있습니다. 생성과 이해 능력 사이에 흥미롭게 역전된 무언가가 있을 수 있습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">모라벡의 역설 <span class="en">Moravec's Paradox</span></h4>
                    <p class="knowledge-desc">높은 수준의 추론은 컴퓨터에게 쉽지만, 감각운동 기술은 어렵다는 관찰입니다. 예를 들어 AI는 체스는 잘 두지만 물체를 집거나 인식하는 것은 어려워합니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">생성 AI 역설 <span class="en">Generative AI Paradox</span></h4>
                    <p class="knowledge-desc">Yejin Choi가 제안한 개념으로, AI가 콘텐츠를 생성하는 능력은 뛰어나지만 깊이 이해하는 능력은 상대적으로 부족하다는 역설입니다. 인간과는 반대 양상을 보입니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 09: AI 안전성과 테스트의 딜레마 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">09</span>
                <h2 class="section-title">AI 안전성과 테스트의 딜레마</h2>
                <p class="question">AI를 의료 같은 중요한 분야에 적용하려면 어떻게 테스트해야 할까요?</p>
                <div class="text-content">
                    <p class="answer">단기적으로는 AI를 과도하게 사용하여 잘못된 조언을 받는 위험이 있고, 장기적으로는 너무 좋아서 문제가 될 수도 있습니다. 제 재단은 의사에게 접근할 수 없는 가난한 사람들을 위한 의사에 해당하는 것을 갖고 싶어 합니다. 하지만 어떻게 테스트할까요? 우리가 여기서 가진 것을 특성화하기 어려울 때 얼마나 신중해야 할까요? 가설적으로 AGI 같은 능력이 존재한다면, 그리고 그것이 정말 좋다면, 기후 변화 같은 인류가 직면한 가장 어려운 질문들에 실제로 답할 수 있을까요? AGI가 정말로 온다면, 실제로 그런 목적에 충분히 좋을까요? 우리는 어떻게든 인류에게 더 나은 혜택을 줄 수 있는 이러한 AI 기술을 만들어야 하지만, 실제로 초신뢰할 만할까요? 얼마나 큰 격차가 있을까요? 지금은 매우 불확실합니다. 우리는 그것이 코앞에 있다고 믿고 싶지만, 특히 인류에게 정말 유익할 수 있는 기술들에 대해서는 말입니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">AGI <span class="en">Artificial General Intelligence</span></h4>
                    <p class="knowledge-desc">인간 수준의 범용 인공지능으로, 특정 작업이 아닌 모든 인지 작업에서 인간 수준 이상의 성능을 보이는 AI입니다. 아직 달성되지 않았으며 실현 시기에 대한 예측이 분분합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 10: 학계와 산업의 균형 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">10</span>
                <h2 class="section-title">학계와 산업의 균형</h2>
                <p class="question">AI 연구가 소수의 대기업에 집중되는 것이 왜 문제인가요?</p>
                <div class="text-content">
                    <p class="answer">불행히도 학계에서 산업계로의 인재 유출이 있습니다. 하지만 실제로 제게는 더 큰 우려가 있습니다. 산업계에 있든 학계에 있든, 많은 사람들이 약간 절망감을 느끼고 있다는 것입니다. '규모가 전부다'라는 강력한 메시지가 현장을 지배하고 있고, GPT-5, 6, 7이 더욱 놀라울 것이며, 이에 대해 할 수 있는 것은 아무것도 없다는 식입니다. 현재 프롬프트 엔지니어링을 주요 연구 초점으로 너무 많이 전환한 것이 있습니다. 저는 진정으로 그것에 대해 걱정합니다. 모두가 같은 일을 하는 것이 좋을 수 있을까요? 호기심으로 더 큰 규모로 무슨 일이 일어나는지 탐구하는 것은 좋지만, 너무 많은 강조가 있고 모든 주요 기업들이 이제 ChatGPT를 따라잡아야 한다고 느낀다는 사실이 있습니다. 많은 친구들로부터 내부적으로 많은 재초점화, 우선순위 재조정이 있다고 들었는데, 이것은 완전히 이해할 만하지만, 이것이 전 세계적인 현상이라면 전혀 건강하지 않습니다. 우리는 AI를 보호하고 더 컴퓨팅 효율적이며 따라서 탄소 발자국도 적은 대안적 방법을 구축하는 데 더 많은 연구 노력을 기울여야 합니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">탄소 발자국 <span class="en">Carbon Footprint</span></h4>
                    <p class="knowledge-desc">활동이나 제품이 배출하는 온실가스의 총량입니다. 대형 AI 모델의 학습과 운영은 막대한 전력을 소비하여 환경에 상당한 영향을 미칩니다.</p>
                </div>
            </aside>
        </article>

        <!-- BONUS SECTION -->
        <div class="section-divider">
            <span class="line"></span>
            <span class="icon">✦</span>
            <span class="line"></span>
        </div>

        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">+</span>
                <h2 class="section-title">AI로 더 나은 세상을</h2>
                <p class="question">AI가 세상을 개선하는 데 어떻게 도움이 될 수 있을까요?</p>
                <div class="text-content single-column">
                    <p class="answer">제 희망적인 생각은 AI가 인간보다 인간을 더 잘 이해하는 것입니다. 그것이 근본적으로 많은 갈등이 있는 이유라고 생각합니다. 많은 불일치가 있고, AI를 도구로 사용하여 우리 자신에 대해 더 잘 성찰하고, 서로 더 잘 소통하며, 더 평화롭게 공존할 수 있기를 바랍니다. AI가 아직 거기까지 도달하지 않았기 때문에 꿈일 뿐이지만, 만약 AI가 서로를 이해하는 데 도움을 줄 수 있다면, 어쩌면 이 양극화 추세를 역전시킬 수 있다면, 그것은 세상에 엄청난 은혜가 될 것입니다. 많은 사람들이 AI가 세계를 장악하지 않도록 하는 AI 안전성에 대해 걱정하지만, 동시에 어쩌면 갈등을 개선하고 줄이며 이해를 향상시킬 수 있습니다. 그것은 노력할 가치가 있습니다.</p>
                </div>
                
            </div>
        </article>

</main>

{% include magazine/footer.html
   quote="My wishful thought is AI to really better understand humans more than humans ourselves do. I'm hoping that we can use AI as a tool to better reflect about ourselves, and then be able to communicate to each other better, and coexist together more peacefully."
   meta_text="Unconfuse Me with Bill Gates · Episode 05 · November 16, 2023" %}
