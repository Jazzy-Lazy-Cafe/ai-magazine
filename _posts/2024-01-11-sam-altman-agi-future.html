---
layout: magazine
title: "Sam Altman : AGI로 가는 길과 인류의 미래"
description: "OpenAI CEO 샘 알트만이 빌 게이츠와 나눈 대화. AI의 해석 가능성부터 글로벌 규제, 지능의 비용 하락, 그리고 인간 목적의 재정의까지"
date: 2024-01-11
---

{% include magazine/header.html
   logo_text="AI"
   logo_highlight="Future"
   episode_info="Unconfuse Me · Episode 06" %}

{% include magazine/hero-split.html
   label="AGI & FUTURE OF HUMANITY"
   title="지능의 비용을 <span class='highlight'>거의 0</span>으로 만들다"
   subtitle="OpenAI CEO가 말하는 AGI로 가는 여정, 글로벌 규제의 필요성, 그리고 풍요의 시대에 인간이 찾아야 할 새로운 목적"
   guest1_initials="SA"
   guest1_name="Sam Altman"
   guest1_role="CEO, OpenAI"
   guest2_initials="BG"
   guest2_name="Bill Gates"
   guest2_role="Host, Unconfuse Me"
   visual_text="AGI"
   original_link="https://www.gatesnotes.com/meet-bill/my-podcasts/reader/unconfuse-me-podcast-with-guest-sam-altman" %}

{% include magazine/highlight-box.html
   label="핵심 통찰"
   text="I think we will be able to understand these networks. The little bits we do understand have been very helpful in improving these things. These are the stupidest the models will ever be."
   translation="우리는 이 네트워크들을 이해할 수 있을 것입니다. 우리가 이해하는 작은 부분들이 시스템 개선에 매우 도움이 되었습니다. 지금이 이 모델들이 가장 멍청한 시점입니다." %}

<!-- Interview Context -->
<section class="interview-context fade-in">
    <h3 class="context-title">인터뷰 배경</h3>
    <p class="context-content">샘 알트만은 OpenAI의 CEO이자 전 Y Combinator 대표로, ChatGPT를 세상에 선보인 장본인입니다. 이 인터뷰는 2024년 1월 빌 게이츠의 팟캐스트 'Unconfuse Me'에서 진행되었으며, 인터뷰 직후 알트만의 해임과 복귀라는 드라마틱한 사건이 있었습니다. AI의 기술적 발전, 글로벌 규제, 인류의 미래에 대한 두 기술 거장의 심도 깊은 대화를 담고 있습니다.</p>
</section>

<!-- Main Content Grid -->
<main class="magazine-grid">

        <!-- SECTION 01: AI 모델의 해석 가능성 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">01</span>
                <h2 class="section-title">AI 모델의 해석 가능성</h2>
                <p class="question">우리는 AI가 어떻게 작동하는지 이해할 수 있을까요?</p>
                <div class="text-content">
                    <p class="answer">100% 가능하다고 생각합니다. 인간의 뇌에서 이것을 하려면 매우 어렵습니다. 뉴런이 있고, 연결되어 있고, 연결이 변화하는데 뇌를 해부해서 진화를 관찰할 수는 없습니다. 하지만 AI 모델은 완벽하게 X-ray 촬영할 수 있습니다. 해석 가능성에 대한 아주 좋은 연구가 진행되어 왔고, 시간이 지나면서 더 많아질 것입니다. 현재 우리의 이해 수준은 낮지만, 우리가 이해하는 작은 부분들이 이 시스템을 개선하는 데 매우 도움이 되었습니다. 규모가 너무 방대해서 시간이 걸리지만, 5년 안에 이해할 수 있을 것이라고 확신합니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">해석 가능성 <span class="en">Interpretability</span></h4>
                    <p class="knowledge-desc">AI 모델이 왜 특정 결정을 내리는지 이해하는 연구 분야입니다. 모델 내부의 뉴런 활성화 패턴을 분석하여 '셰익스피어'라는 개념이 어디에 인코딩되어 있는지 같은 질문에 답하려고 합니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">스케일링 법칙 <span class="en">Scaling Laws</span></h4>
                    <p class="knowledge-desc">AI 모델의 성능이 데이터, 연산량, 모델 크기에 따라 예측 가능하게 향상된다는 경험적 법칙입니다. OpenAI는 이를 통해 GPT-4가 학습되기 전에도 성능을 예측할 수 있었습니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 02: 앞으로 2년간의 핵심 마일스톤 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">02</span>
                <h2 class="section-title">앞으로 2년간의 핵심 마일스톤</h2>
                <p class="question">AI 기술의 향후 2년간 가장 중요한 발전은 무엇인가요?</p>
                <div class="text-content">
                    <p class="answer">멀티모달리티가 분명히 중요할 것입니다. 음성 입출력, 이미지, 그리고 결국 비디오까지요. 우리가 이미지와 오디오를 출시했을 때 예상보다 훨씬 강한 반응이 있었습니다. 하지만 가장 중요한 발전 영역은 추론 능력일 것입니다. 현재 GPT-4는 매우 제한적인 방식으로만 추론할 수 있습니다. 또한 신뢰성도 중요합니다. GPT-4에게 질문을 10,000번 하면 그 중 하나는 꽤 좋은 답이지만, 모델이 어느 것이 좋은지 항상 알지는 못합니다. 매번 10,000개 중 최고의 응답을 얻고 싶습니다.</p>
                </div>
                <p class="follow-up-question">개인화와 커스터마이즈도 중요한가요?</p>
                <div class="follow-up-content">
                    <p class="follow-up-answer">매우 중요합니다. 사람들은 GPT-4에서 매우 다른 것을 원합니다. 다른 스타일, 다른 가정들이요. 우리는 이 모든 것을 가능하게 할 것입니다. 또한 사용자의 데이터를 사용할 수 있는 능력, 이메일, 캘린더, 약속 예약 방식을 알고 외부 데이터 소스에 연결되는 것, 이 모든 것이 가장 중요한 개선 영역이 될 것입니다.</p>
                </div>
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">멀티모달리티 <span class="en">Multimodality</span></h4>
                    <p class="knowledge-desc">AI가 텍스트뿐만 아니라 이미지, 음성, 비디오 등 여러 형태의 데이터를 이해하고 생성하는 능력입니다. GPT-4V와 같은 모델이 이미지를 이해하고 DALL-E가 이미지를 생성하는 것이 예시입니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">적응형 컴퓨트 <span class="en">Adaptive Compute</span></h4>
                    <p class="knowledge-desc">질문의 복잡도에 따라 연산량을 다르게 할당하는 방식입니다. 현재는 '리만 가설을 증명하라'와 'The'라는 단어를 생성하는 데 동일한 연산을 사용하지만, 어려운 문제에는 더 많은 연산이 필요합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 03: AI 규제와 글로벌 거버넌스 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">03</span>
                <h2 class="section-title">AI 규제와 글로벌 거버넌스</h2>
                <p class="question">AI에 어떤 종류의 규제가 필요하다고 생각하나요?</p>
                <div class="text-content">
                    <p class="answer">우리는 이제 막 이것을 파악하기 시작하고 있습니다. 이 분야에 너무 많은 규제를 가하기는 매우 쉽습니다. 하지만 만약 우리가 맞고 이 기술이 우리가 생각하는 만큼 발전한다면, 사회와 지정학적 힘의 균형 등 많은 것에 영향을 미칠 것입니다. GPT-4가 아니라 그것의 10만 배, 100만 배 컴퓨팅 파워를 가진 미래의 초강력 시스템에 대해서는 IAEA와 같은 글로벌 규제 기관이 필요합니다. 원자력 에너지에 대해서도 같은 결정을 내렸습니다. 전 세계적 영향의 잠재력 때문에 일종의 글로벌 기관이 필요합니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">IAEA <span class="en">International Atomic Energy Agency</span></h4>
                    <p class="knowledge-desc">국제원자력기구로, 원자력의 평화적 이용을 촉진하고 군사적 목적 전용을 방지하는 국제기구입니다. 샘 알트만은 초강력 AI 시스템에 대해 이와 유사한 글로벌 감독 기관이 필요하다고 제안합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 04: 속도 저하 없는 안전 확보 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">04</span>
                <h2 class="section-title">속도 저하 없는 안전 확보</h2>
                <p class="question">미중 경쟁 속에서 AI 개발 속도를 늦추는 것이 가능한가요?</p>
                <div class="text-content">
                    <p class="answer">속도 저하를 요청하는 것으로 보인다면 정말 어려울 것입니다. 대신 '원하는 대로 하되, 특정 매우 높은 임계값 이상의 컴퓨트 클러스터는 국제 무기 사찰관에 해당하는 것에 제출해야 한다'고 하면 가능합니다. 비용을 고려하면 전 세계에 아마 다섯 개 정도만 해당될 것입니다. 그런 클러스터에서 훈련되는 모델은 안전 감사를 받고, 훈련 중과 배포 전에 일부 테스트를 통과해야 합니다. 올해 세계를 돌며 많은 국가 정상들과 이야기했는데, 이에 대해 거의 보편적인 지지가 있었습니다. 이런 안전 장치가 마련된다면, AI의 긍정적 가능성에 본격적으로 집중할 수 있게 됩니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">컴퓨트 클러스터 <span class="en">Compute Cluster</span></h4>
                    <p class="knowledge-desc">대규모 AI 모델을 훈련하기 위해 수천 개의 GPU를 연결한 슈퍼컴퓨터 시설입니다. GPT-4 수준의 모델을 훈련하려면 수십억 달러 규모의 인프라가 필요하며, 전 세계에 이런 규모의 시설은 극소수입니다.</p>
                </div>
            </aside>
        </article>

{% include magazine/highlight-box.html
   label="유일한 탈출구"
   text="The only way out is through. We have to go do this thing. It's going to happen. This is now an unstoppable technological course. The value is too great."
   translation="유일한 탈출구는 통과하는 것입니다. 우리는 이것을 해야 합니다. 일어날 것입니다. 이것은 이제 멈출 수 없는 기술적 흐름입니다. 가치가 너무 큽니다." %}

        <!-- SECTION 05: AI가 가장 흥분되는 영역 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">05</span>
                <h2 class="section-title">AI가 가장 흥분되는 영역</h2>
                <p class="question">AI의 생산성 향상 중 어떤 영역이 가장 기대되나요?</p>
                <div class="text-content">
                    <p class="answer">우리는 지금 긴 연속적인 곡선 위에 있다는 것을 기억해야 합니다. 현재 AI 시스템은 작업은 할 수 있지만 직업은 못 합니다. 프로그래머를 약 3배 빠르게 만들 수 있는데, 이것이 우리가 가장 흥분하는 카테고리 중 하나입니다. 3배 더 효과적인 프로그래머는 단순히 3배 더 많은 일을 하는 게 아니라, 더 높은 추상화 수준에서 질적으로 완전히 다른 것을 생각할 수 있습니다. 펀치 카드에서 고급 언어로 가는 것이 프로그래밍을 조금 빠르게 한 게 아니라 질적으로 새로운 것을 가능하게 한 것처럼요. 코딩이 현재 가장 흥분되는 영역이고, 헬스케어와 교육도 그 곡선을 따라 올라오고 있습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">AI 에이전트 <span class="en">AI Agent</span></h4>
                    <p class="knowledge-desc">단순 질의응답을 넘어 복잡한 작업을 자율적으로 수행하는 AI 시스템입니다. 샘 알트만은 '이 프로그램 전체를 작성해줘'라고 말하면 몇 가지 질문만 하고 완성하는 에이전트를 상상합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 06: 적응 속도의 도전 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">06</span>
                <h2 class="section-title">적응 속도의 도전</h2>
                <p class="question">AI로 인한 변화에 인류가 적응할 수 있을까요?</p>
                <div class="text-content">
                    <p class="answer">무서운 부분은 적응해야 한다는 것이 아닙니다. 인류는 초적응력이 있습니다. 우리는 이런 대규모 기술 변화를 겪어왔고, 몇 세대에 걸쳐 사람들의 직업이 엄청나게 바뀔 수 있었고, 우리는 그것을 잘 흡수했습니다. 각 기술 혁명은 더 빨라졌고, 이번이 단연 가장 빠를 것입니다. 제가 잠재적으로 약간 무섭다고 느끼는 부분은 사회가 적응해야 하는 속도, 그리고 노동 시장이 변화할 속도입니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">기술 혁명의 가속 <span class="en">Accelerating Technological Revolutions</span></h4>
                    <p class="knowledge-desc">농업 혁명은 수천 년, 산업 혁명은 수백 년, 정보 혁명은 수십 년이 걸렸습니다. AI 혁명은 그보다 훨씬 빠를 것으로 예상되며, 이 속도가 사회 적응의 가장 큰 도전입니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 07: 로봇공학의 미래 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">07</span>
                <h2 class="section-title">로봇공학의 미래</h2>
                <p class="question">AI와 로봇공학은 어떻게 결합될까요?</p>
                <div class="text-content">
                    <p class="answer">로봇공학에 대해 매우 흥분하고 있습니다. 우리는 로봇을 너무 일찍 시작해서 그 프로젝트를 보류해야 했습니다. 잘못된 이유로 어려웠거든요. ML 연구의 어려운 부분을 진전시키는 데 도움이 되지 않았습니다. 나쁜 시뮬레이터와 끊어지는 힘줄 같은 것들을 다루고 있었습니다. 시간이 지나면서 우리는 먼저 지능과 인지가 필요하고, 그 다음에 물리적 세계에 적응하는 방법을 알아낼 수 있다는 것을 깨달았습니다. 하지만 우리는 항상 돌아올 계획이었습니다.</p>
                </div>
                <p class="follow-up-question">블루칼라 일자리에 대한 영향은 어떨까요?</p>
                <div class="follow-up-content">
                    <p class="follow-up-answer">7-10년 전 컨센서스 예측은 블루칼라 일자리가 먼저, 화이트칼라가 두 번째, 창의성은 절대 또는 마지막이었습니다. 인간의 영역이니까요. 분명히 정반대로 갔습니다. 창의적 작업에서 GPT 모델의 환각은 버그가 아니라 기능입니다. 새로운 것을 발견하게 해줍니다. 반면 로봇이 무거운 기계를 옮기게 하려면 정말 정밀해야 합니다. 과학이 그 방향으로 가고 싶지 않을 때가 있습니다. 하지만 기술이 어느 방향으로 가든, 우리가 궁극적으로 걱정해야 할 것들이 있습니다.</p>
                </div>
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">환각 <span class="en">Hallucination</span></h4>
                    <p class="knowledge-desc">AI 모델이 사실이 아닌 정보를 생성하는 현상입니다. 정확성이 필요한 작업에서는 문제지만, 창의적 작업에서는 예상치 못한 아이디어를 제공하는 기능이 될 수 있습니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 08: AGI 시대의 세 가지 우려 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">08</span>
                <h2 class="section-title">AGI 시대의 세 가지 우려</h2>
                <p class="question">AGI가 달성되면 가장 걱정되는 것은 무엇인가요?</p>
                <div class="text-content">
                    <p class="answer">세 가지가 걱정됩니다. 첫째는 나쁜 사람이 시스템을 통제하는 것입니다. 좋은 사람들이 동등하게 강력한 시스템을 가지고 있다면 그 문제를 최소화할 수 있습니다. 둘째는 시스템이 통제권을 가져가는 것인데, 저는 다른 사람들만큼 걱정하지 않습니다. 다른 사람들이 걱정해서 다행입니다. 셋째이자 가장 당혹스러운 것은 인간의 목적입니다. 저는 말라리아 퇴치에 기여하는 것에서 많은 흥분을 얻습니다. 기계가 '빌, 피클볼이나 치러 가세요, 말라리아 퇴치는 제가 할게요. 당신은 느린 사고자일 뿐이에요'라고 말할 때, 철학적으로 혼란스러운 일입니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">AGI <span class="en">Artificial General Intelligence</span></h4>
                    <p class="knowledge-desc">인간 수준의 일반 지능을 가진 AI를 의미합니다. 현재의 AI는 특정 작업에 특화되어 있지만, AGI는 인간처럼 다양한 영역에서 학습하고 추론할 수 있습니다. OpenAI의 궁극적인 목표입니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 09: 희소성 이후의 세계 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">09</span>
                <h2 class="section-title">희소성 이후의 세계</h2>
                <p class="question">풍요의 시대에 인간은 어떻게 목적을 찾을 수 있을까요?</p>
                <div class="text-content">
                    <p class="answer">이것이 이 기술을 연구하는 데 있어 심리적으로 가장 어려운 부분입니다. 저도 그것에서 많은 만족을 얻기 때문입니다. 어떤 의미에서 이것이 제가 할 마지막 어려운 일일 수도 있습니다. 하지만 저는 진심으로 믿습니다. 비록 우리가 무언가를 포기하더라도, 우리보다 더 똑똑한 것들을 갖게 될 것입니다. 이 희소성 이후의 세계에 들어가면 우리는 할 새로운 것들을 찾을 것입니다. 말라리아를 해결하는 대신 어떤 은하가 좋은지 결정하고 그것으로 무엇을 할지 정할지도 모릅니다. 문제가 고갈되지는 않을 것이고, 서로를 위해 충족감을 찾고 일을 하는 다양한 방법도 고갈되지 않을 것입니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">희소성 이후 사회 <span class="en">Post-Scarcity Society</span></h4>
                    <p class="knowledge-desc">지능과 에너지 비용이 거의 0에 가까워지면 도래할 수 있는 사회 형태입니다. 현재 인류의 사고는 희소성을 중심으로 구성되어 있어, 이런 세계를 상상하기조차 어렵다고 빌 게이츠는 말합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 10: 지능 비용의 급락 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">10</span>
                <h2 class="section-title">지능 비용의 급락</h2>
                <p class="question">AI 시스템 운영 비용은 얼마나 빠르게 낮아지고 있나요?</p>
                <div class="text-content">
                    <p class="answer">이미 엄청나게 내려왔습니다. GPT-3는 3년 조금 넘게 출시되었는데, 비용을 40배 낮출 수 있었습니다. 3.5는 거의 10배, 4는 더 새로워서 아직 시간이 적었지만 계속 낮출 것입니다. 우리는 제가 아는 어떤 기술보다 가장 가파른 비용 절감 곡선 위에 있습니다. 무어의 법칙보다 훨씬 좋습니다. 모델을 더 효율적으로 만드는 방법뿐 아니라, 연구를 더 잘 이해하면서 더 작은 모델에 더 많은 지식과 능력을 담을 수 있습니다. 현재 비용에서도, 이것이 가장 높은 비용이 될 것이지만, 월 20달러에 엄청난 GPT-4 접근권을 얻을 수 있고, 20달러 이상의 가치를 얻습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">무어의 법칙 <span class="en">Moore's Law</span></h4>
                    <p class="knowledge-desc">반도체 칩의 트랜지스터 수가 약 2년마다 2배로 증가한다는 경험적 법칙입니다. 샘 알트만은 AI 비용 절감이 이보다 훨씬 빠르다고 주장합니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">지능과 에너지 <span class="en">Intelligence and Energy</span></h4>
                    <p class="knowledge-desc">샘 알트만의 세계 모델에서 삶의 질에 가장 큰 두 가지 입력 요소입니다. 특히 가난한 사람들에게 이 두 비용을 동시에 낮추면 엄청난 개선을 제공할 수 있습니다.</p>
                </div>
            </aside>
        </article>

        <!-- Statistics Section -->
        <section class="full-width-section">
            <div class="stat-card">
                <div class="stat-number">40×</div>
                <div class="stat-label">GPT-3 비용 절감 (3년)</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">~500명</div>
                <div class="stat-label">OpenAI 직원 수</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">$20/월</div>
                <div class="stat-label">GPT-4 구독 비용</div>
            </div>
        </section>

        <!-- SECTION 11: OpenAI의 독특한 여정 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">11</span>
                <h2 class="section-title">OpenAI의 독특한 여정</h2>
                <p class="question">OpenAI는 어떻게 기존 스타트업 공식을 깨고 성공했나요?</p>
                <div class="text-content">
                    <p class="answer">OpenAI는 표준 YC 조언에 완전히 반하는 많은 일을 했습니다. 첫 제품을 출시하기까지 4년 반이 걸렸습니다. 제품이 뭐가 될지 전혀 모르고 회사를 시작했습니다. 사용자와 대화하지 않았습니다. 대부분의 회사에 여전히 그렇게 하라고 권하지 않지만, YC에서 규칙을 배우고 보면서 언제, 어떻게, 왜 그것을 깰 수 있는지 이해할 수 있었습니다. 핵심은 세계 최고의 인재를 모으고, 모두가 AGI 미션에 정렬되어 있는지 확인하고, 그 외에는 사람들이 자기 일을 하게 하는 것이었습니다.</p>
                </div>
                <p class="follow-up-question">Microsoft와의 파트너십은 어떤 역할을 했나요?</p>
                <div class="follow-up-content">
                    <p class="follow-up-answer">실리콘밸리 투자자들은 우리가 필요한 수준으로 지원하지 않았을 것입니다. 제품에 도달하기 전에 연구에 너무 많은 자본을 써야 했기 때문입니다. '결국 모델이 충분히 좋아지면 사람들에게 가치 있을 것이다'라고만 말했습니다. Microsoft와의 파트너십에 매우 감사합니다. 이런 매출-선행 투자는 벤처캐피탈 산업이 잘하는 것이 아니기 때문입니다. 자본 비용이 벤처가 감당할 수 있는 한계에 있었거나 아마 넘어섰습니다.</p>
                </div>
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">Y Combinator <span class="en">Y Combinator</span></h4>
                    <p class="knowledge-desc">실리콘밸리의 가장 유명한 스타트업 액셀러레이터로, Reddit, Dropbox, Airbnb 등을 배출했습니다. 샘 알트만은 2014-2019년 YC의 대표를 역임하며 수천 개의 스타트업을 지켜봤습니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 12: 인재와 미션의 힘 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">12</span>
                <h2 class="section-title">인재와 미션의 힘</h2>
                <p class="question">OpenAI는 어떻게 최고의 인재들을 유지하고 있나요?</p>
                <div class="text-content">
                    <p class="answer">훌륭한 사람들은 정말로 훌륭한 동료들과 함께 일하고 싶어합니다. 거기에는 깊은 중력의 중심이 있습니다. 또한, 모든 회사가 말하는 진부한 소리로 들리겠지만, 사람들이 미션을 정말 깊이 느낍니다. 모든 사람이 AGI 창조의 현장에 있고 싶어합니다. 데모로 저를 계속 놀라게 할 때 그 에너지가 보입니다. 새로운 사람들, 새로운 아이디어들이요. 정말 놀라운 속도로 계속 움직이고 있습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">OpenAI의 규모 <span class="en">OpenAI's Size</span></h4>
                    <p class="knowledge-desc">2024년 초 기준 약 500명의 직원으로 구성된 회사입니다. Google, Microsoft, Apple과 비교하면 매우 작지만, 연구소와 실제 비즈니스, 두 개의 제품을 운영해야 합니다.</p>
                </div>
            </aside>
        </article>

        <!-- BONUS SECTION -->
        <div class="section-divider">
            <span class="line"></span>
            <span class="icon">✦</span>
            <span class="line"></span>
        </div>

        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">+</span>
                <h2 class="section-title">가장 자주 주는 조언</h2>
                <p class="question">샘 알트만이 가장 자주 주는 조언은 무엇인가요?</p>
                <div class="text-content single-column">
                    <p class="answer">대부분의 사람들이 위험에 대해 잘못 보정되어 있다는 것입니다. 사람들은 정말 하고 싶은 일을 하기 위해 편하고 안정적인 직장을 떠나는 것을 두려워합니다. 하지만 그렇게 하지 않으면 나중에 '나는 시작하고 싶었던 회사를 시작하지 않았다, AI 연구자가 되려고 시도하지 않았다'며 인생을 돌아보게 됩니다. 그게 훨씬 더 위험하다고 생각합니다. 관련해서, 무엇을 하고 싶은지 명확히 하고 원하는 것을 요청하는 것이 놀랍도록 멀리 갑니다. 많은 사람들이 원하는 방식으로 시간을 쓰지 못하고 갇혀 있습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">위험의 재보정 <span class="en">Risk Recalibration</span></h4>
                    <p class="knowledge-desc">샘 알트만의 핵심 철학 중 하나입니다. 사람들이 두려워하는 '실패의 위험'보다 '시도하지 않은 후회의 위험'이 더 크다고 주장합니다. 빌 게이츠는 목적의식이 있는 일을 찾으면 더 재미있고 더 큰 영향을 미칠 수 있다고 덧붙입니다.</p>
                </div>
            </aside>
        </article>

</main>

{% include magazine/footer.html
   quote="We're never going to run out of problems, and we're never going to run out of different ways to find fulfillment."
   meta_text="Unconfuse Me · Episode 06 · January 2024" %}
