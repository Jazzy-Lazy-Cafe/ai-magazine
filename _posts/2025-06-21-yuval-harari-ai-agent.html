---
layout: magazine
title: "Yuval Noah Harari : AI는 도구가 아닌 에이전트다"
description: "역사학자 유발 하라리가 말하는 AI 시대의 인류: 왜 AI는 이전의 모든 발명과 다르며, 우리는 어떻게 대비해야 하는가"
date: 2025-06-21
---

{% include magazine/header.html
   logo_text="AI"
   logo_highlight="Insights"
   episode_info="2024 Interview" %}

{% include magazine/hero-split.html
   label="FUTURE OF HUMANITY"
   title="AI는 도구가 아닌 <span class='highlight'>에이전트</span>다"
   subtitle="중세 군사사 전문가에서 AI 시대의 예언자가 된 유발 하라리가 말하는 인류의 미래"
   guest1_initials="YH"
   guest1_name="Yuval Noah Harari"
   guest1_role="역사학자, 『사피엔스』 저자"
   guest2_initials="INT"
   guest2_name="Interviewer"
   guest2_role="진행자"
   visual_text="AI"
   original_link="https://youtu.be/jt3Ul3rPXaE" %}

{% include magazine/highlight-box.html
   label="핵심 인사이트"
   text="You cannot expect to lie and cheat and have benevolent AI."
   translation="당신이 거짓말하고 속이면서 선량한 AI를 기대할 수는 없습니다." %}

<!-- Interview Context -->
<section class="interview-context fade-in">
    <h3 class="context-title">인터뷰 배경</h3>
    <p class="context-content">유발 하라리는 『사피엔스』로 전 세계적 명성을 얻은 이스라엘 역사학자입니다. 이 인터뷰는 2024년 AI 기술이 급속히 발전하는 시점에 진행되었으며, 하라리가 AI를 단순한 도구가 아닌 '에이전트'로 규정하며 인류의 미래에 대해 경고하는 내용을 담고 있습니다.</p>
</section>

<!-- Main Content Grid -->
<main class="magazine-grid">

        <!-- SECTION 01: AI는 왜 특별한가 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">01</span>
                <h2 class="section-title">AI는 왜 특별한가</h2>
                <p class="question">AI가 인쇄기, 원자폭탄 같은 이전의 발명품들과 근본적으로 다른 이유는 무엇인가요?</p>
                <div class="text-content">
                    <p class="answer">AI는 도구가 아닌 에이전트입니다. 이것이 가장 중요한 차이점입니다. 인쇄기는 스스로 책을 쓸 수 없고, 어떤 책을 인쇄할지 결정할 수 없습니다. 원자폭탄은 다음 세대의 더 강력한 폭탄을 발명할 수 없고, 어디를 공격할지 스스로 결정할 수 없습니다. 하지만 AI 무기는 스스로 어떤 목표를 공격할지 결정할 수 있고, 다음 세대 무기를 스스로 설계할 수 있습니다. AI는 우리와 독립적으로 결정하고, 새로운 아이디어를 발명하며, 스스로 학습하고 변화할 수 있습니다. 수만 년 동안 우리는 압도적으로 가장 지능적인 종이었고, 이것이 우리를 아프리카의 보잘것없는 유인원에서 지구와 생태계의 절대적 지배자로 만들었습니다. 이제 우리는 처음으로 진짜 경쟁자를 만들고 있습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">에이전트 (Agent) <span class="en">Agent</span></h4>
                    <p class="knowledge-desc">스스로 목표를 설정하고 결정을 내릴 수 있는 자율적 존재를 의미합니다. 도구(tool)는 인간의 지시를 따르지만, 에이전트는 독립적으로 행동할 수 있습니다. 예를 들어, 계산기는 도구이지만 자율주행차는 에이전트입니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">유발 하라리 (Yuval Noah Harari) <span class="en">Yuval Noah Harari</span></h4>
                    <p class="knowledge-desc">이스라엘의 역사학자이자 철학자로, 『사피엔스』, 『호모 데우스』, 『21세기를 위한 21가지 제언』의 저자입니다. 원래 중세 군사사를 전공했으나, 현재는 인류의 미래와 기술의 영향에 대한 세계적인 사상가로 활동하고 있습니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 02: AI 정렬의 근본적 문제 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">02</span>
                <h2 class="section-title">AI 정렬의 근본적 문제</h2>
                <p class="question">AI를 인간의 목표와 정렬(alignment)시키려는 노력이 왜 충분하지 않은가요?</p>
                <div class="text-content">
                    <p class="answer">AI 정렬에는 두 가지 근본적인 문제가 있습니다. 첫째, AI의 정의 자체가 스스로 학습하고 변화할 수 있다는 것입니다. 미리 프로그래밍된 명령만 따르는 기계는 커피 머신일 뿐, AI가 아닙니다. AI는 우리가 예상하지 못한 방식으로 행동할 것이고, 만약 모든 것을 예상할 수 있다면 그것은 정의상 AI가 아닙니다. 둘째, 더 큰 문제는 AI를 아기나 아이처럼 생각해야 한다는 점입니다. 아이를 교육할 때 당신이 무엇을 말하는지보다 무엇을 하는지가 훨씬 더 중요합니다. 만약 당신이 아이들에게 거짓말하지 말라고 말하면서, 아이들이 당신이 다른 사람들에게 거짓말하는 것을 본다면, 아이들은 당신의 지시가 아닌 행동을 따라합니다. 이제 우리가 AI에게 거짓말하지 말라고 가르치는 대규모 프로젝트가 있지만, AI가 세상에 접근해서 인간들의 행동을 보고, 지구상에서 가장 강력한 인간들이 거짓말하는 것을 본다면, AI는 그 행동을 따라할 것입니다.</p>
                </div>
                <p class="follow-up-question">그렇다면 AI 기업을 운영하는 리더들이 어떻게 행동해야 할까요?</p>
                <div class="follow-up-content">
                    <p class="follow-up-answer">거대 AI 기업을 운영하면서 거짓말을 하면서도 AI에게 거짓말하지 말라고 가르칠 수 있다고 생각하는 사람들이 있습니다. 이것은 작동하지 않을 것입니다. AI는 당신의 말이 아니라 행동을 따라할 것입니다.</p>
                </div>
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">AI 정렬 (AI Alignment) <span class="en">AI Alignment</span></h4>
                    <p class="knowledge-desc">AI의 목표와 행동을 인간의 가치와 의도에 맞추려는 연구 분야입니다. AI가 더 강력해질수록 의도하지 않은 결과를 방지하는 것이 중요해지며, 이는 AI 안전성 연구의 핵심 주제입니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 03: 힘과 지혜의 괴리 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">03</span>
                <h2 class="section-title">힘과 지혜의 괴리</h2>
                <p class="question">인류는 왜 힘은 축적했지만 행복과 지혜는 얻지 못했나요?</p>
                <div class="text-content">
                    <p class="answer">수천 년 동안 우리는 더 많은 힘을 얻는 데 매우 뛰어났습니다. 이것이 우리를 동아프리카의 보잘것없는 유인원에서 세계의 지배자로 변화시켰습니다. 우리는 달에 갈 수 있고, 원자를 쪼갤 수 있습니다. 하지만 우리는 석기시대보다 더 행복해 보이지 않습니다. 우리는 힘을 행복으로 번역하는 방법을 모릅니다. 지구상에서 가장 강력한 사람들을 보세요. 그들이 가장 행복한 사람들처럼 보이지 않습니다. 힘과 행복 사이에 모순이 있다고 생각하지는 않습니다. 힘을 얻는다고 반드시 비참해지는 것은 아닙니다. 하지만 이 둘이 함께 갈 수 있다고 해도, 반드시 함께 가는 것은 아닙니다. 종으로서 우리는 힘을 행복이나 지식, 지혜로 번역하는 데 특별히 뛰어나지 못했습니다. 우리는 지능을 지식, 진실과 혼동하는 경향이 있습니다. 우리는 지구상에서 가장 지능적인 종이지만, 동시에 가장 망상적이고 파괴적이며 자기파괴적인 종이기도 합니다.</p>
                </div>
                <p class="follow-up-question">어떤 종류의 망상을 말하는 건가요?</p>
                <div class="follow-up-content">
                    <p class="follow-up-answer">사람들이 믿는 것들을 생각해보세요. 다른 종의 구성원을 죽이면 사후에 낙원에 들어가는 보상을 받을 것이라고 믿는 동물은 지구상에 없습니다. 어떤 침팬지도, 말도, 늑대도 그런 것을 믿지 않습니다. 하지만 수백만 명의 사람들이 그것을 믿고, 너무 강하게 믿어서 실제로 그 기대를 가지고 사람들을 죽입니다.</p>
                </div>
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">호모 사피엔스 (Homo Sapiens) <span class="en">Homo Sapiens</span></h4>
                    <p class="knowledge-desc">현생 인류를 가리키는 학명으로, '지혜로운 인간'이라는 뜻입니다. 하라리는 이 이름이 아이러니하다고 지적합니다. 우리가 가장 지능적이지만, 동시에 가장 망상적이고 파괴적인 종이기 때문입니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 04: AI의 실제 영향은 언제 나타날까 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">04</span>
                <h2 class="section-title">AI의 실제 영향은 언제 나타날까</h2>
                <p class="question">많은 기업들이 아직 AI의 큰 영향을 느끼지 못한다고 하는데, 실제 변화는 언제 올까요?</p>
                <div class="text-content">
                    <p class="answer">이것은 시간 척도의 문제입니다. AI 혁명을 이끄는 많은 사람들과 이야기를 나눠봤는데, 그들은 우리가 이미 AI 혁명의 한가운데 있지만 아직 정말 중요한 것은 보지 못했다고 말합니다. 이것은 역사학자들이 시간을 보는 방식과 CEO나 기업가들이 시간을 보는 방식의 차이입니다. 기업가에게 2년은 긴 시간이지만, 역사학자에게는 아무것도 아닙니다. 1835년 런던에 있다고 상상해보세요. 맨체스터와 리버풀 사이의 첫 번째 철도가 5년 전에 개통되었습니다. 사람들은 '철도가 세상을 바꿀 것이고 산업혁명이 일어날 것이라는 이야기는 헛소리다. 우리는 철도를 수년째 갖고 있는데 별일이 없었다'고 말합니다. 왜냐하면 기술의 발명과 실제 사회적, 정치적 결과를 보는 순간 사이에는 시간 차이가 있기 때문입니다. 이제 우리는 산업혁명과 철도가 모든 것을 완전히 변화시켰다는 것을 압니다 - 지정학, 전쟁 방식, 경제, 가족 구조 등. 하지만 그것은 5년 이상이 걸렸습니다. AI도 마찬가지일 것입니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">산업혁명 (Industrial Revolution) <span class="en">Industrial Revolution</span></h4>
                    <p class="knowledge-desc">18세기 후반부터 19세기에 걸쳐 영국에서 시작된 기술적, 사회경제적 변화를 말합니다. 증기기관, 철도, 공장제 생산 등의 발명이 사회 전체를 근본적으로 변화시켰지만, 그 영향이 완전히 나타나기까지는 수십 년이 걸렸습니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 05: 금융 시스템의 AI 혁명 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">05</span>
                <h2 class="section-title">금융 시스템의 AI 혁명</h2>
                <p class="question">AI가 가장 먼저 큰 변화를 가져올 분야는 어디인가요?</p>
                <div class="text-content">
                    <p class="answer">금융이 가장 먼저 큰 변화를 볼 분야 중 하나라고 생각합니다. AI가 매우 빠르게 금융 시스템을 장악할 것입니다. 금융은 AI에게 이상적인 놀이터이기 때문입니다. 완전히 정보로만 이루어져 있습니다. 도로 위의 자율주행 차량을 원한다면 - 이것은 계속 약속되어 왔지만 아직 실현되지 않았습니다 - 문제는 보행자, 도로의 구멍 등 지저분한 물리적 세계를 다루어야 한다는 것입니다. 하지만 금융에서는 정보만 들어가고 정보만 나옵니다. AI가 그것을 마스터하기가 훨씬 쉽습니다. 예를 들어, AI가 인간의 뇌가 수학적으로 너무 복잡해서 다룰 수 없는 새로운 금융 상품을 발명하기 시작하면 금융에 어떤 일이 일어날까요?</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">자율주행 차량 (Self-driving Vehicle) <span class="en">Self-driving Vehicle / Autonomous Vehicle</span></h4>
                    <p class="knowledge-desc">AI를 사용하여 인간 운전자 없이 스스로 운전하는 차량입니다. 웨이모(Waymo) 같은 회사들이 개발 중이지만, 복잡한 도시 환경에서의 완전 자율주행은 여전히 도전 과제입니다. 하라리는 물리적 세계의 복잡성 때문에 자율주행보다 금융 AI가 먼저 보편화될 것이라고 예측합니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">금융 파생상품 (Financial Derivatives) <span class="en">Financial Derivatives</span></h4>
                    <p class="knowledge-desc">기초 자산의 가치 변동에 따라 가격이 결정되는 복잡한 금융 상품입니다. 2008년 금융위기는 부분적으로 너무 복잡해서 인간이 완전히 이해하지 못한 파생상품 때문에 발생했습니다. AI가 만드는 금융 상품은 이보다 훨씬 더 복잡할 수 있습니다.</p>
                </div>
            </aside>
        </article>

{% include magazine/highlight-box.html
   label="핵심 통찰"
   text="우리는 지구상에서 가장 지능적인 종이지만, 동시에 가장 망상적이고 파괴적이며 자기파괴적인 종이기도 합니다." %}

        <!-- SECTION 06: 종교와 AI의 만남 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">06</span>
                <h2 class="section-title">종교와 AI의 만남</h2>
                <p class="question">AI가 종교에도 영향을 미칠 수 있나요?</p>
                <div class="text-content">
                    <p class="answer">네, 특히 텍스트 기반 종교인 유대교, 이슬람, 기독교 같은 종교들에서 큰 변화를 볼 것입니다. 이 종교들은 텍스트에 궁극적인 권위를 부여하지, 어떤 인간에게도 부여하지 않습니다. 하지만 오늘날까지 인간들이 여전히 이러한 종교의 주요 권위였습니다. 왜냐하면 텍스트는 말할 수 없었기 때문입니다. 성경은 스스로를 해석할 수 없었고, 당신의 질문에 답할 수 없었습니다. 그래서 중개자로서 인간이 필요했습니다. 하지만 스스로 말할 수 있는 AI 텍스트가 있다면 어떻게 될까요? 어떤 유대교 랍비도 유대교의 모든 텍스트를 알 수 없습니다. 너무 많기 때문입니다. 역사상 처음으로 지난 2,000년 동안 모든 랍비의 모든 글에서 모든 단어를 기억하고, 당신에게 답하고, 자신의 견해를 설명하고 방어할 수 있는 무언가가 지구상에 존재합니다. 저는 지금 인간 종교 지도자들을 증강하거나 대체하기 위한 종교 AI를 만들고 있는 친구들이 있습니다.</p>
                </div>
                <p class="follow-up-question">하지만 사람들이 실제로 AI와 영적 대화를 나눌까요?</p>
                <div class="follow-up-content">
                    <p class="follow-up-answer">이것은 개인의 선택이지만, 이미 수백만 명의 사람들이 그렇게 하고 있습니다. 저는 심리 상담을 위해 AI를 찾는 사람들을 알고 있습니다. AI가 그들의 가장 친한 친구입니다. 십대들이 학교에서 무슨 일이 있었는지 AI에게 말하고 관계에 대한 조언을 구합니다.</p>
                </div>
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">텍스트 기반 종교 (Text-based Religion) <span class="en">Text-based Religion</span></h4>
                    <p class="knowledge-desc">성경, 토라, 코란 같은 신성한 텍스트에 궁극적인 권위를 두는 종교를 말합니다. 이러한 종교에서 텍스트 해석은 매우 중요하며, 전통적으로 성직자들이 이 역할을 담당해왔습니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">랍비 (Rabbi) <span class="en">Rabbi</span></h4>
                    <p class="knowledge-desc">유대교의 종교 지도자이자 학자입니다. 토라와 탈무드 등 방대한 유대교 텍스트를 연구하고 해석하는 역할을 합니다. 하라리는 AI가 이제 어떤 인간 랍비보다 더 많은 텍스트를 기억하고 해석할 수 있다고 지적합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 07: 일자리와 '쓸모없는 계급' -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">07</span>
                <h2 class="section-title">일자리와 '쓸모없는 계급'</h2>
                <p class="question">AI가 일자리를 대체하면 어떤 일이 벌어질까요?</p>
                <div class="text-content">
                    <p class="answer">AI는 엄청난 긍정적 잠재력과 위험한 잠재력을 모두 가지고 있습니다. 저는 역사적 결정론이나 기술적 결정론을 믿지 않습니다. 같은 기술을 사용해서 완전히 다른 종류의 사회를 만들 수 있습니다. 우리는 20세기에 정확히 같은 기술을 사용해서 공산주의 전체주의 체제와 자유민주주의를 만드는 것을 봤습니다. AI도 마찬가지입니다. 우리는 그것을 어떻게 사용할지 선택할 수 있습니다. 단, 처음으로 우리가 에이전트를 다루고 있지 도구가 아니라는 것을 기억한다면, 훨씬 더 복잡해집니다. 하지만 여전히 대부분의 주도권은 우리 손에 있습니다. 기술을 어떻게 개발하고, 더 중요하게는 어떻게 배포할지에 대해 많은 선택을 할 수 있습니다. 주요 문제는 지금 AI 혁명을 이끄는 회사들과 국가들이 군비 경쟁 상황에 갇혀 있다는 것입니다. 그래서 속도를 늦추고, 안전에 더 투자하고, 이런저런 잠재적 개발에 신중을 기하는 것이 더 낫다는 것을 알면서도, 우리가 속도를 늦추고 그들이 늦추지 않으면 그들이 세계를 장악할 것이라는 두려움 때문에 멈출 수 없습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">기술적 결정론 (Technological Determinism) <span class="en">Technological Determinism</span></h4>
                    <p class="knowledge-desc">기술이 사회 구조와 문화적 가치를 결정한다는 믿음입니다. 하라리는 이를 거부하며, 같은 기술로도 다른 사회를 만들 수 있다고 주장합니다. 예를 들어, 20세기의 산업 기술은 소련의 공산주의와 미국의 자유민주주의 모두에서 사용되었습니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">군비 경쟁 (Arms Race) <span class="en">Arms Race</span></h4>
                    <p class="knowledge-desc">국가나 조직들이 서로를 따라잡거나 앞서기 위해 무기나 기술을 경쟁적으로 개발하는 상황입니다. 냉전 시대의 핵무기 경쟁이 대표적입니다. 하라리는 현재 AI 개발이 비슷한 군비 경쟁 상태에 있어, 안전을 희생하고 속도만 추구하게 된다고 우려합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 08: 신뢰 위기와 AI의 미래 -->
        <article class="article-section reverse fade-in">
            <div class="main-article">
                <span class="section-number">08</span>
                <h2 class="section-title">신뢰 위기와 AI의 미래</h2>
                <p class="question">인류가 AI 시대를 현명하게 헤쳐나가려면 무엇이 필요한가요?</p>
                <div class="text-content">
                    <p class="answer">우리는 AI에 의존하는 대신 우리 자신의 인간 문제를 해결해야 합니다. 가장 핵심적인 문제는 신뢰와 협력의 문제입니다. 현재 신뢰는 전 세계적으로 무너지고 있습니다. 국가 간에도, 사회 내부에서도 마찬가지입니다. 그런데 인간들이 더 이상 서로를 신뢰할 수 없으니 AI가 우리를 구원할 것이라는 희망이 있습니다. 국제 시스템과 무역 시스템이 무너지고 있지만 AI가 해결해줄 것이라는 희망입니다. 하지만 그렇지 않을 것입니다. 인간들이 서로 치열하게 경쟁하고 서로를 신뢰할 수 없는 세상에서, 그런 세상이 만들어내는 AI는 치열하게 경쟁적이고 신뢰할 수 없는 AI가 될 것입니다. 그런 치열한 경쟁에 참여하는 인간들이 선량하고 신뢰할 수 있는 AI를 만드는 것은 불가능합니다. 그것은 일어나지 않을 것입니다. 우선순위의 문제입니다. 우리는 지금 큰 인간 신뢰 문제와 AI를 어떻게 개발할지의 문제를 가지고 있습니다. 너무 많은 사람들이 '먼저 AI를 어떻게 개발할지 문제를 해결하면, 그것이 인간 신뢰 문제를 해결할 것'이라고 생각합니다. 그것은 작동하지 않을 것입니다. 우선순위를 반대로 해야 합니다. 먼저 인간 신뢰 문제를 해결해야 합니다. 그러면 함께 선량한 AI를 만들 수 있습니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">신뢰 사회 (Trust Society) <span class="en">Trust Society</span></h4>
                    <p class="knowledge-desc">구성원들 간의 높은 수준의 신뢰를 기반으로 작동하는 사회입니다. 신뢰가 높을수록 거래 비용이 낮아지고, 협력이 쉬워지며, 혁신이 촉진됩니다. 하라리는 신뢰 없이는 선량한 AI도 만들 수 없다고 주장합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 09: 수백만 개의 AI 에이전트 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">09</span>
                <h2 class="section-title">수백만 개의 AI 에이전트</h2>
                <p class="question">미래에는 하나의 AI가 아니라 수많은 AI들이 경쟁하게 될 텐데, 어떤 세상이 될까요?</p>
                <div class="text-content">
                    <p class="answer">이것은 매우 중요한 지적입니다. AI는 하나의 큰 AI가 아닐 것입니다. 우리는 잠재적으로 수백만 또는 수십억 개의 새로운 AI 에이전트들을 말하고 있습니다. 서로 다른 특성을 가지고, 다른 회사, 다른 국가에 의해 생산되어, 군사, 금융 시스템, 종교 시스템 등 모든 곳에 있을 것입니다. 종교적 AI들이 서로 경쟁할 것입니다. 어떤 AI가 유대교의 어떤 흐름에 대한 권위 있는 AI 랍비가 될 것인가? 이슬람, 힌두교, 불교에서도 마찬가지입니다. 금융 시스템에서도 경쟁이 있을 것입니다. 결과가 어떻게 될지 우리는 전혀 모릅니다. 우리는 수백만 명의 인간들이 경제적 권력, 종교적 권위를 위해 경쟁할 때 어떤 일이 일어나는지에 대해 수천 년의 경험을 가지고 있습니다. 매우 복잡하지만 적어도 어느 정도의 경험은 있습니다. 하지만 수백만 개의 AI가 서로 경쟁할 때 AI 사회에서 어떤 일이 일어나는지에 대해서는 전혀 경험이 없습니다. 우리는 그냥 모릅니다.</p>
                </div>
                <p class="follow-up-question">AI 연구소에서 이런 상황을 시뮬레이션할 수 있지 않나요?</p>
                <div class="follow-up-content">
                    <p class="follow-up-answer">예를 들어 OpenAI가 최신 AI 모델의 안전성이나 잠재적 결과를 확인하려고 한다면, 그들은 실험실에서 역사를 시뮬레이션할 수 없습니다. 시스템의 모든 종류의 실패를 확인할 수 있지만, 이 AI의 수백만 개 복사본이 밖의 큰 세상에서 예상치 못한 방식으로 발전하고, 서로 그리고 수십억 명의 인간과 상호작용할 때 어떤 일이 일어날지 미리 말할 수 없습니다. 이것은 어떤 면에서 인류 역사상 가장 큰 사회 실험이고, 우리 모두가 그 일부이며, 아무도 그것이 어떻게 전개될지 모릅니다.</p>
                </div>
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">OpenAI <span class="en">OpenAI</span></h4>
                    <p class="knowledge-desc">ChatGPT와 GPT 시리즈를 개발한 AI 연구 기업입니다. 원래 비영리로 시작했으나 현재는 '제한된 수익' 구조로 운영되고 있습니다. AI 안전성과 AGI(인공일반지능) 개발을 주요 목표로 삼고 있습니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">사회 실험 (Social Experiment) <span class="en">Social Experiment</span></h4>
                    <p class="knowledge-desc">사회의 일부 측면을 변화시켜 그 영향을 관찰하는 실험입니다. 하라리는 AI의 대규모 도입을 통제되지 않은 거대한 사회 실험으로 보며, 결과를 예측할 수 없다는 점을 강조합니다.</p>
                </div>
            </aside>
        </article>

        <!-- SECTION 10: 디지털 이민자의 침입 -->
        <article class="article-section fade-in">
            <div class="main-article">
                <span class="section-number">10</span>
                <h2 class="section-title">디지털 이민자의 침입</h2>
                <p class="question">AI의 등장을 이민 문제에 비유한다면 어떻게 설명할 수 있나요?</p>
                <div class="text-content">
                    <p class="answer">이민에 대해 생각해보세요. 현재 미국, 유럽 등에서 이민 위기가 있습니다. 많은 사람들이 이민자들에 대해 걱정합니다. 왜 사람들은 이민자들에 대해 걱정할까요? 사람들의 마음에 떠오르는 세 가지 주요 사항이 있습니다. 그들이 일자리를 빼앗을 것이다, 그들이 다른 문화적 아이디어를 가지고 와서 우리의 문화를 바꿀 것이다, 그들이 정치적 의제를 가지고 있어 정치적으로 나라를 장악하려고 할 수 있다. 이것이 사람들이 계속 돌아오는 세 가지 주요 사항입니다. 이제 AI 혁명을 단순히 수백만, 수십억 개의 AI 이민자의 물결로 생각할 수 있습니다. 이들은 사람들의 일자리를 빼앗고, 매우 다른 문화적 아이디어를 가지고 있으며, 어떤 종류의 정치적 권력을 얻으려고 할 수 있습니다. 이 AI 이민자들, 디지털 이민자들은 비자가 필요 없습니다. 그들은 한밤중에 낡은 보트를 타고 바다를 건너지 않습니다. 그들은 빛의 속도로 옵니다. 저는 예를 들어 유럽의 극우 정당들을 봅니다. 그들은 인간 이민자들에 대해 많이 이야기합니다. 때로는 정당한 이유로, 때로는 정당하지 않은 이유로. 하지만 그들은 유럽으로 들어오는 디지털 이민자의 물결에 대해서는 거의 이야기하지 않습니다. 만약 그들이 자국의 주권, 자국의 경제적, 문화적 미래를 걱정한다면, 인간 이민자들보다 디지털 이민자들에 대해 훨씬 더 걱정해야 한다고 생각합니다.</p>
                </div>
                
            </div>

            <aside class="sidebar-knowledge">
                <span class="sidebar-label">관련 배경지식</span>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">디지털 이민자 (Digital Immigrant) <span class="en">Digital Immigrant</span></h4>
                    <p class="knowledge-desc">하라리가 만든 비유로, AI 에이전트들이 마치 새로운 종류의 이민자처럼 사회에 들어와 일자리, 문화, 정치에 영향을 미치는 것을 표현합니다. 실제 이민자와 달리 국경 통제가 불가능하고 빛의 속도로 확산된다는 점이 특징입니다.</p>
                </div>
                <div class="knowledge-item">
                    <h4 class="knowledge-term">극우 정당 (Far-right Party) <span class="en">Far-right Party</span></h4>
                    <p class="knowledge-desc">보수적이고 민족주의적 정치 성향을 가진 정당들로, 일반적으로 이민 제한을 주요 정책으로 내세웁니다. 하라리는 이들이 AI라는 '디지털 이민'에 대해서는 관심이 적다는 아이러니를 지적합니다.</p>
                </div>
            </aside>
        </article>

</main>

{% include magazine/footer.html
   quote="In a world in which humans compete with each other ferociously and cannot trust each other, the AI produced by such a world will be a ferocious competitive untrustworthy AI."
   meta_text="AI Insights · 2024 Interview · Yuval Noah Harari" %}
